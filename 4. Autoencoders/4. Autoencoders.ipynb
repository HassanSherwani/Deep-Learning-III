{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for dimensionality reduction, by training the network to ignore signal “noise”. Along with the reduction side, a reconstructing side is learnt, where the autoencoder tries to generate from the reduced encoding a representation as close as possible to its original input, hence its name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)-Import key modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Reshape\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import Callback\n",
    "import numpy as np\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR To use wandb on Windows, you need to run the command \"wandb run python <your_train_script>.py\"\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init()\n",
    "config = run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.encoding_dim = 32\n",
    "config.epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# no y label as we are using X to represent x as outpur\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1754ebd2208>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets see what the images look like\n",
    "\n",
    "image = x_train[50, :].reshape((28, 28)) # checking a random row i.e 50 for image\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(config.encoding_dim, activation='relu'))\n",
    "model.add(Dense(28*28, activation='sigmoid'))\n",
    "model.add(Reshape((28,28)))\n",
    "model.compile(optimizer='adam', loss='mse') # as we working on performance so mse is better than accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 784)               25872     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28)            0         \n",
      "=================================================================\n",
      "Total params: 50,992\n",
      "Trainable params: 50,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. For visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Images(Callback):\n",
    "      def on_epoch_end(self, epoch, logs):\n",
    "            indices = np.random.randint(self.validation_data[0].shape[0], size=8)\n",
    "            test_data = self.validation_data[0][indices]\n",
    "            pred_data = self.model.predict(test_data)\n",
    "            run.history.row.update({\n",
    "                  \"examples\": [\n",
    "                        wandb.Image(np.hstack([data, pred_data[i]]), caption=str(i))\n",
    "                        for i, data in enumerate(test_data)]\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0321 - val_loss: 0.0161\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0134 - val_loss: 0.0113\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0102 - val_loss: 0.0099\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0102 - val_loss: 0.0099\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train, x_train,\n",
    "                epochs=config.epochs,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('auto.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4)- Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(x_train, x_test):\n",
    "    # Function to add some random noise\n",
    "    noise_factor = 1.0\n",
    "    x_train_noisy = x_train + np.random.normal(loc=0.0, scale=noise_factor, size=x_train.shape) \n",
    "    x_test_noisy = x_test + np.random.normal(loc=0.0, scale=noise_factor, size=x_test.shape) \n",
    "    \n",
    "    x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "    x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "    return x_train_noisy, x_test_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_images(epoch, logs):\n",
    "    # Function to show the before and after images at each step\n",
    "    indices = np.random.randint(x_test_noisy.shape[0], size=8)\n",
    "    test_data = x_test_noisy[indices]\n",
    "    pred_data = np.clip(model.predict(test_data), 0, 1)\n",
    "    wandb.log({\n",
    "            \"examples\": [\n",
    "                wandb.Image(np.hstack([data, pred_data[i]]), caption=str(i))\n",
    "                for i, data in enumerate(test_data)]\n",
    "        }, commit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "(x_train_noisy, x_test_noisy) = add_noise(x_train, x_test)\n",
    "img_width = x_train.shape[1]\n",
    "img_height = x_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(img_width, img_height)))\n",
    "model.add(Dense(config.encoding_dim, activation=\"relu\"))\n",
    "model.add(Dense(img_width*img_height, activation=\"sigmoid\"))\n",
    "model.add(Reshape((img_width, img_height)))\n",
    "model.compile(loss='mse', optimizer='adam',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 784)               25872     \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 28, 28)            0         \n",
      "=================================================================\n",
      "Total params: 50,992\n",
      "Trainable params: 50,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0402 - mean_squared_error: 0.0402 - val_loss: 0.0258 - val_mean_squared_error: 0.0258\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.0220 - val_mean_squared_error: 0.0220\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0221 - mean_squared_error: 0.0221 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0215 - mean_squared_error: 0.0215 - val_loss: 0.0210 - val_mean_squared_error: 0.0210\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0209 - val_mean_squared_error: 0.0209\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0213 - mean_squared_error: 0.0213 - val_loss: 0.0208 - val_mean_squared_error: 0.0208\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.0207 - val_mean_squared_error: 0.0207\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0204 - val_mean_squared_error: 0.0204\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.0204 - val_mean_squared_error: 0.0204\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0204 - val_mean_squared_error: 0.0204\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.0204 - val_mean_squared_error: 0.0204\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0202 - val_mean_squared_error: 0.0202\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.0200 - val_mean_squared_error: 0.0200\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0203 - mean_squared_error: 0.0203 - val_loss: 0.0199 - val_mean_squared_error: 0.0199\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0202 - mean_squared_error: 0.0202 - val_loss: 0.0199 - val_mean_squared_error: 0.0199\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0202 - mean_squared_error: 0.0202 - val_loss: 0.0198 - val_mean_squared_error: 0.0198\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0197 - val_mean_squared_error: 0.0197\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0197 - val_mean_squared_error: 0.0197\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0197 - val_mean_squared_error: 0.0197\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.0196 - val_mean_squared_error: 0.0196\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.0198 - val_mean_squared_error: 0.0198\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.0200 - val_mean_squared_error: 0.0200\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.0196 - val_mean_squared_error: 0.0196\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.0196 - val_mean_squared_error: 0.0196\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.0196 - val_mean_squared_error: 0.0196\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.0195 - val_mean_squared_error: 0.0195\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.0197 - val_mean_squared_error: 0.0197\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.0195 - val_mean_squared_error: 0.0195\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train_noisy, x_train, epochs=30, validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both lower value of loss from real image to encoded output show that encoded image is clear, less noisey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
